import React, { useState, useEffect, useRef } from "react";
import "./TalkingScreen.css";
import { HiOutlineMicrophone } from "react-icons/hi2";
import { FaRegStopCircle, FaRegPlayCircle } from "react-icons/fa";
//-----------------------------------‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ wakeword-----------------------------------------
import { usePorcupine } from "@picovoice/porcupine-react";
import HelloAvisKeywordModel from "../Hello_avis";
import ThankYouAvisKeywordModel from "../Thank-you-Avis";
import modelParams from "../porcupine_params";

function TalkingScreen({ onSpeakingChange, onClose }) {
  const [scale, setScale] = useState(1);
  const [hasSound, setHasSound] = useState(false);
  const [showStopIcon, setShowStopIcon] = useState(true);
  const audioChunksRef = useRef([]);
  const mediaRecorderRef = useRef(null);
  const [isRecording, setIsRecording] = useState(false);
  const silenceTimeoutRef = useRef(null);
  const maxRecordTimeoutRef = useRef(null);
  const { keywordDetection, isLoaded, init, start, stop } = usePorcupine();
  const wsRef = useRef(null); // ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® websocket
  const [isSpeaking, setIsSpeaking] = useState(false);
  const playTimeoutRef = useRef(null);
  const [isListening, setIsListening] = useState(true);  // ‡πÄ‡∏û‡∏¥‡πà‡∏° state isListening
  const HelloavisRef = useRef(false); // ‡πÉ‡∏ä‡πâ useRef ‡πÅ‡∏ó‡∏ô useState
  const [isPaused, setIsPaused] = useState(false);  // ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
  const [isPlayingResponse, setIsPlayingResponse] = useState(true);
  const lastKeywordRef = useRef(null); // ‡πÉ‡∏ä‡πâ ref ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ keyword ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î




// ----------------------------------- WebSocket ------------------------------------------
const connectWebSocket = (url = "ws://localhost:8000") => {
  if (isPaused || (wsRef.current && wsRef.current.readyState === WebSocket.OPEN)) return;

  console.log("üîå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ WebSocket...");
  wsRef.current = new WebSocket(url);

  wsRef.current.onopen = () => {
    console.log("‚úÖ WebSocket connected, re-enabling wake word...");
    // setIsListening(true);  // ‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î wake word ‡πÉ‡∏´‡∏°‡πà
    // start();
};
  
  wsRef.current.onclose = () => {
      console.log("üîÑ ‡∏õ‡∏¥‡∏î WebSocket ‡πÅ‡∏•‡πâ‡∏ß.");
  };

  wsRef.current.onerror = (error) => console.error("‚ö†Ô∏è WebSocket error:", error);
};

// üì§ ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡πà‡∏≤‡∏ô WebSocket ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
const safeSendMessage = (message) => {
  if (!wsRef.current) {
      console.warn("üö´ WebSocket ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á");
      return;
  }

  if (wsRef.current.readyState === WebSocket.OPEN) {
      console.log("üì® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡πà‡∏≤‡∏ô WebSocket:", message);
      wsRef.current.send(JSON.stringify(message));
  } else if (wsRef.current.readyState === WebSocket.CONNECTING) {
      console.warn("‚è≥ WebSocket ‡∏¢‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏£‡∏≠ 500ms ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà...");
      setTimeout(() => safeSendMessage(message), 500);
  } else {
      console.error("‚ùå WebSocket ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ:", wsRef.current.readyState);
  }
};

useEffect(() => {
  connectWebSocket(); // ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ WebSocket ‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
  return () => wsRef.current?.close(); // ‚ùå ‡∏õ‡∏¥‡∏î WebSocket ‡πÄ‡∏°‡∏∑‡πà‡∏≠ component unmount
}, []);



useEffect(() => {
  if (isPlayingResponse === false) { // ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    console.log("‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡∏ü‡∏±‡∏á wake word ‡πÉ‡∏´‡∏°‡πà...");
    setIsPaused(false); // ‡πÄ‡∏õ‡∏¥‡∏î wake word ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
    setIsListening(true);
    start(); // ‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡∏ü‡∏±‡∏á wake word
  }
}, [isPlayingResponse]);

useEffect(() => {
  if (!isLoaded) {
    init("pGO4BAYiyE5xOsIbk5ybzw38zI1oTal4m5vqHkR+XGfEiNwpL8IGLw==", [
      { base64: HelloAvisKeywordModel, label: "Hello Avis" },
      { base64: ThankYouAvisKeywordModel, label: "Thank you Avis" },
    ], { base64: modelParams }).then(() => start());
  }
}, [isLoaded, init, start]);

useEffect(() => { 
  if (!keywordDetection || !isListening) return;

  // ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£ trigger ‡∏ã‡πâ‡∏≥
  if (lastKeywordRef.current === keywordDetection.label) return;

  console.log("üîç Detected keyword:", keywordDetection.label);
  lastKeywordRef.current = keywordDetection.label; // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
  console.log(lastKeywordRef.current)

  if (lastKeywordRef.current === "Hello Avis") {
    safeSendMessage({ command: "hello_avis" });
    HelloavisRef.current = true;
    setIsPaused(true);
    wsRef.current?.close();
    setTimeout(startRecording, 3500);
  } else if (lastKeywordRef.current === "Thank you Avis") {
    safeSendMessage({ command: "thank_you_avis" });
    console.log("üëã Goodbye!");
    lastKeywordRef.current = null;
    wsRef.current?.close();
    stop(); // ‡∏´‡∏¢‡∏∏‡∏î wake word
    stopRecording()
    if (typeof onClose === "function") {
      onClose();  // ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏¥‡∏î
    }
  }
}, [keywordDetection, isListening]);


const handleAudioProcessing = (stream) => {
  if (!HelloavisRef.current) return; // ‚ùå ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô wake word ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

  console.log("üéôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á...");
  const recorder = new MediaRecorder(stream);

  recorder.ondataavailable = (e) => {
      if (e.data.size > 0 && HelloavisRef.current) {
          console.log("üîπ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á chunk...");
          audioChunksRef.current.push(e.data);
      }
  };

  recorder.onstop = async () => {
      console.log("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á");
      if (audioChunksRef.current.length === 0) return;

      console.log("üéµ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á...");
      const audioBlob = new Blob(audioChunksRef.current, { type: "audio/wav" });

      console.log("üì® ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ API...");
      sendAudioToAPI(audioBlob);

      // üîÑ **‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î**
      audioChunksRef.current = [];
  };

  return recorder;
};

// üé§ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
const startRecording = async () => {
  if (mediaRecorderRef.current?.state === "recording") return;
  setShowStopIcon(false);
  console.log("üéôÔ∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á...");
  

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  mediaRecorderRef.current = handleAudioProcessing(stream);
  mediaRecorderRef.current.start();
  setIsRecording(true);
  maxRecordTimeoutRef.current = setTimeout(stopRecording, 10000);
};

// üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
const stopRecording = () => {
  if (!isRecording || !mediaRecorderRef.current) return;
  console.log("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á");
  mediaRecorderRef.current.stop();
  setIsRecording(false);
  setShowStopIcon(true);
};

// üì® ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ API
const sendAudioToAPI = async (audioBlob) => {
  try {
      console.log("üì® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ API...");
      const formData = new FormData();
      formData.append("audioData", audioBlob, "audio.webm");

      const response = await fetch("https://api.gowajee.ai/v1/speech-to-text/pulse/transcribe", {
          method: "POST",
          headers: { "x-api-key": "gwj_live_68e8664be460418ab4eee60e7eb60ca0_hbooe" },
          body: formData,
      });

      if (response.ok) {
          const result = await response.json();
          const text = result.output.results.map((item) => item.transcript).join(" ");
          console.log("üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ:", text);
          sendTextToLocalServer(text);
      }
  } catch (error) {
      console.error("‚ùå Error processing audio:", error);
  }
};

// üì© ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ Local Server
const sendTextToLocalServer = async (text) => {
  try {
      console.log("üì© ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ Local Server:", text);

      const response = await fetch("http://localhost:5000/call_llm", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text }),
      });

      if (response.ok) {
          const result = await response.json();
          console.log("üîä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å AI...");
          await playVoice(result.responses);
      }else{
        const text = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
        console.log("üîä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å AI...");
        await playVoice(text);
      }
  } catch (error) {
      console.error("‚ùå Error sending text:", error);
  }
};

const playVoice = async (text) => {
  try {
    if (!HelloavisRef.current) return;

    stopRecording();
    setIsSpeaking(true);
    // setIsListening(false);
    stop();
    setIsPaused(true);
    lastKeywordRef.current = null; // üîÑ ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏Ñ‡πà‡∏≤ keyword ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ
    console.log(lastKeywordRef.current)

    console.log("üîä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á:", text);

    const speechSynthesisUtterance = new SpeechSynthesisUtterance(text);
    
    // ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ
    speechSynthesisUtterance.rate = 0.8;    // ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
    speechSynthesisUtterance.volume = 0.9;  // ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    speechSynthesisUtterance.pitch = 1.0;   // ‡πÇ‡∏ó‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á

    // ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    const voices = speechSynthesis.getVoices();
    speechSynthesisUtterance.voice = voices.find(voice => voice.name.includes("Google ‡πÑ‡∏ó‡∏¢"));

    speechSynthesis.speak(speechSynthesisUtterance);

    speechSynthesisUtterance.onend = () => {
      console.log("üîÑ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° websocket ‡πÉ‡∏´‡∏°‡πà...");
      connectWebSocket();
      console.log("üîÑ ‡πÄ‡∏õ‡∏¥‡∏î wake word ‡πÉ‡∏´‡∏°‡πà...");
      setIsPlayingResponse(false)
      setIsPaused(false);
      HelloavisRef.current = false;

      setTimeout(() => {
        // setIsListening(true);
        start();
      }, 1500);  // ‚úÖ ‡∏£‡∏≠ 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏õ‡∏¥‡∏î wake word ‡πÉ‡∏´‡∏°‡πà
    };

  } catch (error) {
    console.error("‚ùå Error playing voice:", error);
  }
};




  
  //-------------------------------------------
    //-----------------------------------‡πÇ‡∏Ñ‡πâ‡∏î process ‡πÄ‡∏™‡∏µ‡∏¢‡∏á-------------------------------------
    useEffect(() => {
      const setupAudio = async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const audioContext = new (window.AudioContext || window.webkitAudioContext)();
          const analyser = audioContext.createAnalyser();
          const microphone = audioContext.createMediaStreamSource(stream);
          const processor = audioContext.createScriptProcessor(256, 1, 1);
  
          analyser.smoothingTimeConstant = 0.8;
          analyser.fftSize = 1024;
  
          microphone.connect(analyser);
          analyser.connect(processor);
          processor.connect(audioContext.destination);
  
          processor.onaudioprocess = function () {
            const array = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(array);
            const average = array.reduce((sum, value) => sum + value, 0) / array.length;
            const volume = Math.min(average / 100, 1);
  
            if (isRecording) {
              setScale(1 + volume);
              setHasSound(volume > 0.1);
  
              if (volume > 0.1) {
                clearTimeout(silenceTimeoutRef.current);
                silenceTimeoutRef.current = setTimeout(() => {
                  stopRecording();
                }, 3000);
              }
            }
          };
  
          return stream;
        } catch (error) {
          console.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á:", error);
        }
      };
  
      setupAudio();
    }, [isRecording]);


  return (
    <div style={{ display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center', height: '100vh' }}>
      <div
        className="circle"
        style={{
          transform: `scale(${isRecording ? scale : 1})`,
          backgroundColor: isRecording ? (hasSound ? "white" : "gray") : "gray",
        }}
      >
        <HiOutlineMicrophone size={120} color="black" />
      </div>

      {/* Recording / Stop icons */}
      <div style={{ position: "absolute", bottom: "50px", display: "flex", justifyContent: "flex-end", width: "100%", paddingRight: "355px" }}>
        {showStopIcon ? (
          <FaRegStopCircle size={120} style={{ cursor: "pointer", color: "gray" }} />
        ) : (
          <FaRegPlayCircle 
            onClick={startRecording} 
            size={120} 
            style={{ cursor: "pointer", color: "green" }} 
          />
        )}
      </div>
    </div>
  );
}
export default TalkingScreen;